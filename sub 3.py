# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uDp2GdB-bbr0szJ6f8wxP2L9V7Tyy5eu

Nama : Ahmad Sholihin

Email : asholeeqeen41@gmail.com
"""

!pip install -U -q kaggle
!mkdir -p ~/.kaggle

from google.colab import files
files.upload()

!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset
!ls

#Import Library
import zipfile
import os
import shutil
from sklearn.model_selection import train_test_split 
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.models import Model,Sequential
from keras.optimizers import Adam

# Ekstraksi pada file zip sebelumnya
local_zip = '/content/face-expression-recognition-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

#Delete beberapa folder train yang tidak dibutuhkan
!rm -rf '/content/images/train/angry'
!rm -rf '/content/images/train/neutral'
!rm -rf '/content/images/train/disgust'
!rm -rf '/content/images/train/fear'
!rm -rf '/content/images/train/surprise'

#Delete beberapa folder validation yang tidak dibutuhkan
!rm -rf '/content/images/validation/angry'
!rm -rf '/content/images/validation/neutral'
!rm -rf '/content/images/validation/disgust'
!rm -rf '/content/images/validation/fear'
!rm -rf '/content/images/validation/surprise'

train_folder = '/content/images/train'
validation_folder = '/content/images/validation'

#Augmentasi dan generate gambar
train_datagen = ImageDataGenerator(rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')
 
test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

#Preprocessing data with generator
train_generator = train_datagen.flow_from_directory(
        train_folder,  
        target_size=(48, 48), 
        batch_size=8,
        class_mode='binary')
validation_generator = test_datagen.flow_from_directory(
        validation_folder, 
        target_size=(48, 48),  
        batch_size=8, 
        class_mode='binary')

#CNN Architecture Model sequentials (Maxpooling and convolutional layer), flatten to make single array
from keras.layers import Dense, Input, Dropout, Flatten, Conv2D, Activation, MaxPooling2D
from keras.models import Model, Sequential
from keras.optimizers import Adam

# Sequential Model
model = Sequential()

# Conv 1
model.add(Conv2D(64,(3,3), input_shape=(48, 48,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Conv 2
model.add(Conv2D(128,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Conv 3
model.add(Conv2D(256,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Conv 4
model.add(Conv2D(512,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flattening
model.add(Flatten())

# Fully connected layer 1
model.add(Dense(1024))
model.add(Activation('relu'))

# Fully connected layer 2
model.add(Dense(1024))
model.add(Activation('relu'))

model.add(Dense(1, activation='sigmoid'))

opt = Adam(learning_rate=0.0001)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

#Callback untuk mencegah overfitting dengan menghentikan training, apabila telah terpenuhi
class reduceOverfitting(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.93 and logs.get('val_accuracy') > 0.93 ):
      print("\nStopped! Akurasi training dan validasi sudah mencapai 93% dan 93%")
      self.model.stop_training = True
stop = reduceOverfitting()

model.summary()

trainmodel = model.fit(
    train_generator,
    steps_per_epoch = train_generator.n//train_generator.batch_size, 
    epochs = 30,
    validation_data = validation_generator,
    validation_steps = validation_generator.n//validation_generator.batch_size,
    verbose =2,       
      callbacks=[stop] 
)

#Accuracy Plot
plt.plot(trainmodel.history['accuracy'], label='Train Accuracy')
plt.plot(trainmodel.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy Plot')
plt.ylabel('Accuracy Value')
plt.xlabel('Epoch') 
plt.legend(loc="lower right")
plt.show()

#Loss Plot
plt.plot(trainmodel.history['loss'], label='Train Loss')
plt.plot(trainmodel.history['val_loss'], label='Val Loss')
plt.title('Loss Plot')
plt.ylabel('Loss Value')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()